# Lecture11
-----
-----
1. CUDA执行模型
  - 异构主机 （CPU） 和设备 （GPU） 应用程序 C 程序
  - 主机 C 代码中的串行部件
  - 设备内核代码中的并行部分
2. 数据并行性，执行算法
   - 对数据进行分区，然后将计算与数据相关联
   - 任务由多个线程执行
3. CUDA 内核由线程网格（数组）执行。
   - 网格中的所有线程都运行相同的内核代码 （单个程序多个数据）。
   - 一个线程数组被划分为多个块，这些块分布在不同的 SM 上。
   - 块中的线程通过共享内存、原子操作和 barrier 同步进行协作。
   - 每个线程都有用于计算内存地址和做出控制决策的索引。
4. 线程块：可扩展的合作
   i=blockldx.x*blockDimx.x+threadldx.x
   C[i]=A[i]+B[i];

5. Warp
   - Warp作为调度单位，实施决策，不是 CUDA 编程模型的一部分
   - Warp 是 SM 中的调度单元
   - warp 中的线程在 SIMD 中执行
   - 未来的 GPU 在每个 Warp 中可能具有不同数量的线程
   - eg：有三个块分进一个SM ，每个块有256个进程，问这个SM有多少个Warp:256/32=8,8*3=24个。
6. 向量加法内核，设备代码：
   -  __global__ void vecAddKernel(float* A, float* B, float* C, int n)
{
int i = threadIdx.x+blockDim.x*blockIdx.x; if(i<n) C[i] = A[i] + B[i];
}
------
7. 函数声明
   - __device__
   - __global__
   - __host__
   - global 定义内核函数。
   - 每个 “__” 由两个下划线字符组成。
   - 内核函数必须返回 void。
   - device 和 host 可以一起使用。
   - 如果单独使用，host 是可选的。
8. 主机里面有常量内存和全局内存
9. 主机代码可以：将数据传输到每个网格全局内存或从每个网格全局内存传输数据
10. ***cudaMalloc（）***
在设备全局内存中分配对象
11. ***cudaFree（）***
从设备全局内存中释放对象
12. ***cudaMemcpy（）***
   - 内存数据传输
   - 四个因素：
     - 指向目标的指针
     - 指向源的指针
     - 复制的字节数
     - 转移类型/方向
-----

***向量加法主机代码***
- void vecAdd(float *h_A, float *h_B, float *h_C, int n) {
float *d_A, *d_B, *d_C; int size = n * sizeof(float); 
cudaMalloc((void **) &d_A, size); cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
cudaMalloc((void **) &d_B, size);
cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice); cudaMalloc((void **) &d_C, size);
// Kernel invocation code – to be shown later
cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);
cudaFree(d_A); cudaFree(d_B); cudaFree (d_C);
- void vecAdd(float* h_A, float* h_B, float* h_C, int n)
{
// d_A, d_B, d_C allocations and copies omitted // Run ceil(n/256.0) blocks of 256 threads each
vecAddKernel<<<ceil(n/256.0),256>>>(d_A, d_B, d_C, n);
}
256.0指***网格尺寸区块总数***
第二个256指***块尺寸中线程数***
- void vecAdd(float* h_A, float* h_B, float* h_C, int n)
{ // d_A, d_B, d_C allocations and copies omitted // Run ceil(n/256.0) blocks of 256 threads each vecAddKernel<<<ceil(n/256.0),256>>>(d_A, d_B, d_C, n);
}
***ceiling功能确保有足够的线程覆盖所有元素***